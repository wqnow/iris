{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iris01.ipynb（副本）",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/wqnow/iris/blob/master/iris01_ipynb%EF%BC%88%E5%89%AF%E6%9C%AC%EF%BC%89.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "ELMhgv_Wwn1P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1169
        },
        "outputId": "ca68ff80-28fa-483c-e76e-7c5a3ecf71a2"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "print(iris.data.shape)\n",
        "print(iris.DESCR)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 4)\n",
            "Iris Plants Database\n",
            "====================\n",
            "\n",
            "Notes\n",
            "-----\n",
            "Data Set Characteristics:\n",
            "    :Number of Instances: 150 (50 in each of three classes)\n",
            "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
            "    :Attribute Information:\n",
            "        - sepal length in cm\n",
            "        - sepal width in cm\n",
            "        - petal length in cm\n",
            "        - petal width in cm\n",
            "        - class:\n",
            "                - Iris-Setosa\n",
            "                - Iris-Versicolour\n",
            "                - Iris-Virginica\n",
            "    :Summary Statistics:\n",
            "\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "                    Min  Max   Mean    SD   Class Correlation\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
            "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
            "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
            "    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "    :Class Distribution: 33.3% for each of 3 classes.\n",
            "    :Creator: R.A. Fisher\n",
            "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
            "    :Date: July, 1988\n",
            "\n",
            "This is a copy of UCI ML iris datasets.\n",
            "http://archive.ics.uci.edu/ml/datasets/Iris\n",
            "\n",
            "The famous Iris database, first used by Sir R.A Fisher\n",
            "\n",
            "This is perhaps the best known database to be found in the\n",
            "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
            "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
            "data set contains 3 classes of 50 instances each, where each class refers to a\n",
            "type of iris plant.  One class is linearly separable from the other 2; the\n",
            "latter are NOT linearly separable from each other.\n",
            "\n",
            "References\n",
            "----------\n",
            "   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\n",
            "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
            "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
            "   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\n",
            "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
            "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
            "     Structure and Classification Rule for Recognition in Partially Exposed\n",
            "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
            "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
            "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
            "     on Information Theory, May 1972, 431-433.\n",
            "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
            "     conceptual clustering system finds 3 classes in the data.\n",
            "   - Many, many more ...\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "npsNoemq7gtg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "data = load_iris()\n",
        "features = data['data']\n",
        "feature_names = data['feature_names']\n",
        "target = data['target']\n",
        "\n",
        "\n",
        "pairs = [(0,1),(0,2),(0,3),(1,2),(1,3),(2,3)]\n",
        "#数据每50种一类，target中一共有三种，对第一种，取features中的前五十行，t的范围range(3)（0.1.2）\n",
        "#marker标记“>ox”分别为三角圈叉，c颜色。\n",
        "#索引，features[target==0,0]为前五十行第一列的数据\n",
        "for i,(p0,p1) in enumerate(pairs):\n",
        "    plt.subplot(2,3,i+1)#enumerate返回的索引值i是从0开始的。subplot（2，3，1）表示两行三列的第一个图\n",
        "\n",
        "    for t,marker,c in zip(range(3),\">ox\",\"rgb\"):\n",
        "        plt.scatter(features[target == t,p0], features[target == t,p1], marker=marker, c=c)\n",
        "    plt.xlabel(feature_names[p0])\n",
        "    plt.ylabel(feature_names[p1])\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "plt.savefig (r'C:\\Users\\Administrator\\Pictures\\one.jpg')\n",
        "#提取所有的花瓣长度数据，150个\n",
        "plength=features[:,2]\n",
        "\n",
        "#提取 setosa 和 非setosa 的花瓣长度，我把原文稍微修改了一下，比较好理解\n",
        "#需要了解target与features的对应关系。\n",
        "is_setosa=(target==0)\n",
        "setosa_plength=plength[is_setosa]\n",
        "other_plength=plength[~is_setosa]\n",
        "\n",
        "#找出 setosa 花瓣的最大长度，和 非setosa花瓣的最小长度\n",
        "max_setosa=setosa_plength.max()\n",
        "min_non_setosa=other_plength.min()\n",
        "\n",
        "#根据下面输出的数据可知 setosa 花瓣的最大长度，和 非setosa花瓣的最小长度没有重合\n",
        "#因此如果一朵花的花瓣长度小于2的话，那么是setosa的可能性就非常大。\n",
        "print('Maximun of setosa: {0}.'.format(max_setosa)) #输出值是1.9\n",
        "print('Minimum of others: {0}.'.format(min_non_setosa)) #输出值是3.\n",
        "#这里就是给出区别setasa和其他花的模型。"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "Boka-cISLyPa",
        "outputId": "b8e58c9f-6a77-496a-faa7-cd81ccf22e39"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Data sets\n",
        "IRIS_TRAINING = \"iris_training.csv\"\n",
        "IRIS_TRAINING_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
        "\n",
        "IRIS_TEST = \"iris_test.csv\"\n",
        "IRIS_TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
        "\n",
        "def main():\n",
        "    # If the training and test sets aren't stored locally, download them.\n",
        "    if not os.path.exists(IRIS_TRAINING):\n",
        "         raw = urllib.request.urlopen(IRIS_TRAINING_URL).read().decode()\n",
        "    with open(IRIS_TRAINING, \"w\") as f:\n",
        "        f.write(raw)\n",
        "    if not os.path.exists(IRIS_TEST):\n",
        "        raw = urllib.request.urlopen(IRIS_TEST_URL).read().decode()\n",
        "    with open(IRIS_TEST, \"w\") as f:\n",
        "        f.write(raw)\n",
        "    # Load datasets.\n",
        "    training_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
        "        filename=IRIS_TRAINING,\n",
        "        target_dtype=np.int,\n",
        "        features_dtype=np.float32)\n",
        "    test_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
        "        filename=IRIS_TEST,\n",
        "        target_dtype=np.int,\n",
        "        features_dtype=np.float32)\n",
        "    # Specify that all features have real-value data\n",
        "    feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=4)]\n",
        "    # Build 3 layer DNN with 10, 20, 10 units respectively.\n",
        "    classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,\n",
        "                                          hidden_units=[10, 20, 10],\n",
        "                                          n_classes=3,\n",
        "                                          model_dir=\"/tmp/iris_model\")\n",
        "    \n",
        "    # Define the training inputs\n",
        "    def get_train_inputs():\n",
        "      x = tf.constant(training_set.data)\n",
        "      y = tf.constant(training_set.target)\n",
        "      return x, y\n",
        "  \n",
        "    # Fit model.\n",
        "    classifier.fit(input_fn=get_train_inputs, steps=2000)\n",
        "    \n",
        "    # Define the test inputs\n",
        "    def get_test_inputs():\n",
        "      x = tf.constant(test_set.data)\n",
        "      y = tf.constant(test_set.target)\n",
        "      return x, y\n",
        "  \n",
        "    # Evaluate accuracy.\n",
        "    accuracy_score = classifier.evaluate(input_fn=get_test_inputs,\n",
        "                                     steps=1)[\"accuracy\"]\n",
        "    print(\"\\nTest Accuracy: {0:f}\\n\".format(accuracy_score))\n",
        "    # Classify two new flower samples.\n",
        "    \n",
        "    def new_samples():\n",
        "      return np.array(\n",
        "            [[6.4, 3.2, 4.5, 1.5],\n",
        "            [5.8, 3.1, 5.0, 1.7]], dtype=np.float32)\n",
        "  \n",
        "    predictions = list(classifier.predict(input_fn=new_samples))    \n",
        "    print(\n",
        "          \"New Samples, Class Predictions:    {}\\n\"\n",
        "          .format(predictions))\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "  main()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-ac1c0e94f547>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-ac1c0e94f547>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m          \u001b[0mraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIRIS_TRAINING_URL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIRIS_TRAINING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIRIS_TEST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIRIS_TEST_URL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'raw' referenced before assignment"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "rxcK25UaL-l5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2213
        },
        "outputId": "7158c91c-bdef-4ab3-a1f9-937e94b0ec13"
      },
      "cell_type": "code",
      "source": [
        "raw = urllib.request.urlopen(IRIS_TRAINING_URL).read().decode()\n",
        "print(raw)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "120,4,setosa,versicolor,virginica\n",
            "6.4,2.8,5.6,2.2,2\n",
            "5.0,2.3,3.3,1.0,1\n",
            "4.9,2.5,4.5,1.7,2\n",
            "4.9,3.1,1.5,0.1,0\n",
            "5.7,3.8,1.7,0.3,0\n",
            "4.4,3.2,1.3,0.2,0\n",
            "5.4,3.4,1.5,0.4,0\n",
            "6.9,3.1,5.1,2.3,2\n",
            "6.7,3.1,4.4,1.4,1\n",
            "5.1,3.7,1.5,0.4,0\n",
            "5.2,2.7,3.9,1.4,1\n",
            "6.9,3.1,4.9,1.5,1\n",
            "5.8,4.0,1.2,0.2,0\n",
            "5.4,3.9,1.7,0.4,0\n",
            "7.7,3.8,6.7,2.2,2\n",
            "6.3,3.3,4.7,1.6,1\n",
            "6.8,3.2,5.9,2.3,2\n",
            "7.6,3.0,6.6,2.1,2\n",
            "6.4,3.2,5.3,2.3,2\n",
            "5.7,4.4,1.5,0.4,0\n",
            "6.7,3.3,5.7,2.1,2\n",
            "6.4,2.8,5.6,2.1,2\n",
            "5.4,3.9,1.3,0.4,0\n",
            "6.1,2.6,5.6,1.4,2\n",
            "7.2,3.0,5.8,1.6,2\n",
            "5.2,3.5,1.5,0.2,0\n",
            "5.8,2.6,4.0,1.2,1\n",
            "5.9,3.0,5.1,1.8,2\n",
            "5.4,3.0,4.5,1.5,1\n",
            "6.7,3.0,5.0,1.7,1\n",
            "6.3,2.3,4.4,1.3,1\n",
            "5.1,2.5,3.0,1.1,1\n",
            "6.4,3.2,4.5,1.5,1\n",
            "6.8,3.0,5.5,2.1,2\n",
            "6.2,2.8,4.8,1.8,2\n",
            "6.9,3.2,5.7,2.3,2\n",
            "6.5,3.2,5.1,2.0,2\n",
            "5.8,2.8,5.1,2.4,2\n",
            "5.1,3.8,1.5,0.3,0\n",
            "4.8,3.0,1.4,0.3,0\n",
            "7.9,3.8,6.4,2.0,2\n",
            "5.8,2.7,5.1,1.9,2\n",
            "6.7,3.0,5.2,2.3,2\n",
            "5.1,3.8,1.9,0.4,0\n",
            "4.7,3.2,1.6,0.2,0\n",
            "6.0,2.2,5.0,1.5,2\n",
            "4.8,3.4,1.6,0.2,0\n",
            "7.7,2.6,6.9,2.3,2\n",
            "4.6,3.6,1.0,0.2,0\n",
            "7.2,3.2,6.0,1.8,2\n",
            "5.0,3.3,1.4,0.2,0\n",
            "6.6,3.0,4.4,1.4,1\n",
            "6.1,2.8,4.0,1.3,1\n",
            "5.0,3.2,1.2,0.2,0\n",
            "7.0,3.2,4.7,1.4,1\n",
            "6.0,3.0,4.8,1.8,2\n",
            "7.4,2.8,6.1,1.9,2\n",
            "5.8,2.7,5.1,1.9,2\n",
            "6.2,3.4,5.4,2.3,2\n",
            "5.0,2.0,3.5,1.0,1\n",
            "5.6,2.5,3.9,1.1,1\n",
            "6.7,3.1,5.6,2.4,2\n",
            "6.3,2.5,5.0,1.9,2\n",
            "6.4,3.1,5.5,1.8,2\n",
            "6.2,2.2,4.5,1.5,1\n",
            "7.3,2.9,6.3,1.8,2\n",
            "4.4,3.0,1.3,0.2,0\n",
            "7.2,3.6,6.1,2.5,2\n",
            "6.5,3.0,5.5,1.8,2\n",
            "5.0,3.4,1.5,0.2,0\n",
            "4.7,3.2,1.3,0.2,0\n",
            "6.6,2.9,4.6,1.3,1\n",
            "5.5,3.5,1.3,0.2,0\n",
            "7.7,3.0,6.1,2.3,2\n",
            "6.1,3.0,4.9,1.8,2\n",
            "4.9,3.1,1.5,0.1,0\n",
            "5.5,2.4,3.8,1.1,1\n",
            "5.7,2.9,4.2,1.3,1\n",
            "6.0,2.9,4.5,1.5,1\n",
            "6.4,2.7,5.3,1.9,2\n",
            "5.4,3.7,1.5,0.2,0\n",
            "6.1,2.9,4.7,1.4,1\n",
            "6.5,2.8,4.6,1.5,1\n",
            "5.6,2.7,4.2,1.3,1\n",
            "6.3,3.4,5.6,2.4,2\n",
            "4.9,3.1,1.5,0.1,0\n",
            "6.8,2.8,4.8,1.4,1\n",
            "5.7,2.8,4.5,1.3,1\n",
            "6.0,2.7,5.1,1.6,1\n",
            "5.0,3.5,1.3,0.3,0\n",
            "6.5,3.0,5.2,2.0,2\n",
            "6.1,2.8,4.7,1.2,1\n",
            "5.1,3.5,1.4,0.3,0\n",
            "4.6,3.1,1.5,0.2,0\n",
            "6.5,3.0,5.8,2.2,2\n",
            "4.6,3.4,1.4,0.3,0\n",
            "4.6,3.2,1.4,0.2,0\n",
            "7.7,2.8,6.7,2.0,2\n",
            "5.9,3.2,4.8,1.8,1\n",
            "5.1,3.8,1.6,0.2,0\n",
            "4.9,3.0,1.4,0.2,0\n",
            "4.9,2.4,3.3,1.0,1\n",
            "4.5,2.3,1.3,0.3,0\n",
            "5.8,2.7,4.1,1.0,1\n",
            "5.0,3.4,1.6,0.4,0\n",
            "5.2,3.4,1.4,0.2,0\n",
            "5.3,3.7,1.5,0.2,0\n",
            "5.0,3.6,1.4,0.2,0\n",
            "5.6,2.9,3.6,1.3,1\n",
            "4.8,3.1,1.6,0.2,0\n",
            "6.3,2.7,4.9,1.8,2\n",
            "5.7,2.8,4.1,1.3,1\n",
            "5.0,3.0,1.6,0.2,0\n",
            "6.3,3.3,6.0,2.5,2\n",
            "5.0,3.5,1.6,0.6,0\n",
            "5.5,2.6,4.4,1.2,1\n",
            "5.7,3.0,4.2,1.2,1\n",
            "4.4,2.9,1.4,0.2,0\n",
            "4.8,3.0,1.4,0.1,0\n",
            "5.5,2.4,3.7,1.0,1\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zGqE6IOaxdeQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "  if not os.path.exists(IRIS_TRAINING):\n",
        "       raw = urllib.request.urlopen(IRIS_TRAINING_URL).read().decode()\n",
        "  with open(IRIS_TRAINING, \"w\") as f:\n",
        "      f.write(raw)\n",
        "  if not os.path.exists(IRIS_TEST):\n",
        "      raw = urllib.request.urlopen(IRIS_TEST_URL).read().decode()\n",
        "  with open(IRIS_TEST, \"w\") as f:\n",
        "      f.write(raw)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}